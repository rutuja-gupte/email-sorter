{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "880fa174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:\n",
      "CHAT\n",
      "SENT\n",
      "INBOX\n",
      "IMPORTANT\n",
      "TRASH\n",
      "DRAFT\n",
      "SPAM\n",
      "CATEGORY_FORUMS\n",
      "CATEGORY_UPDATES\n",
      "CATEGORY_PERSONAL\n",
      "CATEGORY_PROMOTIONS\n",
      "CATEGORY_SOCIAL\n",
      "STARRED\n",
      "UNREAD\n"
     ]
    }
   ],
   "source": [
    "%run quickstart2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8c8d710b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessed. Yay!\n",
      "['<div dir=\"ltr\"><p style=\"border:0px solid rgb(227,227,227);box-sizing:border-box;margin:1.25em 0px;color:rgb(13,13,13);font-family:Söhne,ui-sans-serif,system-ui,-apple-system,&quot;Segoe UI&quot;,Roboto,Ubuntu,Cantarell,&quot;Noto Sans&quot;,sans-serif,&quot;Helvetica Neue&quot;,Arial,&quot;Apple Color Emoji&quot;,&quot;Segoe UI Emoji&quot;,&quot;Segoe UI Symbol&quot;,&quot;Noto Color Emoji&quot;;font-size:16px\">Dear [Recipient&#39;s Name],</p><p style=\"border:0px solid rgb(227,227,227);box-sizing:border-box;margin:1.25em 0px;color:rgb(13,13,13);font-family:Söhne,ui-sans-serif,system-ui,-apple-system,&quot;Segoe UI&quot;,Roboto,Ubuntu,Cantarell,&quot;Noto Sans&quot;,sans-serif,&quot;Helvetica Neue&quot;,Arial,&quot;Apple Color Emoji&quot;,&quot;Segoe UI Emoji&quot;,&quot;Segoe UI Symbol&quot;,&quot;Noto Color Emoji&quot;;font-size:16px\">I hope this email finds you well. As we strive to uphold our commitment to environmental sustainability, I am writing to propose several initiatives aimed at reducing our ecological footprint within our workplace. In light of the growing global concerns regarding climate change and environmental degradation, it is imperative that we take proactive measures to mitigate our impact on the planet.</p><p style=\"border:0px solid rgb(227,227,227);box-sizing:border-box;margin:1.25em 0px;color:rgb(13,13,13);font-family:Söhne,ui-sans-serif,system-ui,-apple-system,&quot;Segoe UI&quot;,Roboto,Ubuntu,Cantarell,&quot;Noto Sans&quot;,sans-serif,&quot;Helvetica Neue&quot;,Arial,&quot;Apple Color Emoji&quot;,&quot;Segoe UI Emoji&quot;,&quot;Segoe UI Symbol&quot;,&quot;Noto Color Emoji&quot;;font-size:16px\">After conducting thorough research and consulting with various experts in the field, I have identified several areas where we can implement sustainable practices effectively. These initiatives not only align with our corporate values but also have the potential to yield significant long-term benefits for both our company and the environment.</p><ol style=\"border:0px solid rgb(227,227,227);box-sizing:border-box;list-style:none;margin:1.25em 0px;padding:0px;display:flex;color:rgb(13,13,13);font-family:Söhne,ui-sans-serif,system-ui,-apple-system,&quot;Segoe UI&quot;,Roboto,Ubuntu,Cantarell,&quot;Noto Sans&quot;,sans-serif,&quot;Helvetica Neue&quot;,Arial,&quot;Apple Color Emoji&quot;,&quot;Segoe UI Emoji&quot;,&quot;Segoe UI Symbol&quot;,&quot;Noto Color Emoji&quot;;font-size:16px\"><li style=\"border:0px solid rgb(227,227,227);box-sizing:border-box;margin-bottom:0px;margin-top:0px;padding-left:0.375em;display:block;min-height:28px\"><p style=\"border:0px solid rgb(227,227,227);box-sizing:border-box;margin:0px\">Energy Efficiency:</p><ul style=\"border:0px solid rgb(227,227,227);box-sizing:border-box;list-style:disc;margin:0px 0px 0px 1rem;padding:0px;display:flex\"><li style=\"border:0px solid rgb(227,227,227);box-sizing:border-box;margin:0px;padding-left:0.375em;display:block;min-height:28px\">Installation of energy-efficient LED lighting throughout our office premises.</li><li style=\"border:0px solid rgb(227,227,227);box-sizing:border-box;margin:0px;padding-left:0.375em;display:block;min-height:28px\">Implementation of power-saving settings on computers and other electronic devices.</li><li style=\"border:0px solid rgb(227,227,227);box-sizing:border-box;margin:0px;padding-left:0.375em;display:block;min-height:28px\">Encouragement of employees to switch off lights and equipment when not in use.</li></ul></li><li style=\"border:0px solid rgb(227,227,227);box-sizing:border-box;margin-bottom:0px;margin-top:0px;padding-left:0.375em;display:block;min-height:28px\"><p style=\"border:0px solid rgb(227,227,227);box-sizing:border-box;margin:0px\">Waste Reduction:</p><ul style=\"border:0px solid rgb(227,227,227);box-sizing:border-box;list-style:disc;margin:0px 0px 0px 1rem;padding:0px;display:flex\"><li style=\"border:0px solid rgb(227,227,227);box-sizing:border-box;margin:0px;padding-left:0.375em;display:block;min-height:28px\">Introduction of a comprehensive recycling program for paper, plastic, glass, and electronic waste.</li><li style=\"border:0px solid rgb(227,227,227);box-sizing:border-box;margin:0px;padding-left:0.375em;display:block;min-height:28px\">Promotion of digital documentation and communication to minimize paper usage.</li><li style=\"border:0px solid rgb(227,227,227);box-sizing:border-box;margin:0px;padding-left:0.375em;display:block;min-height:28px\">Provision of reusable kitchenware and utensils to reduce single-use plastic consumption in the office pantry.</li></ul></li><li style=\"border:0px solid rgb(227,227,227);box-sizing:border-box;margin-bottom:0px;margin-top:0px;padding-left:0.375em;display:block;min-height:28px\"><p style=\"border:0px solid rgb(227,227,227);box-sizing:border-box;margin:0px\">Transportation:</p><ul style=\"border:0px solid rgb(227,227,227);box-sizing:border-box;list-style:disc;margin:0px 0px 0px 1rem;padding:0px;display:flex\"><li style=\"border:0px solid rgb(227,227,227);box-sizing:border-box;margin:0px;padding-left:0.375em;display:block;min-height:28px\">Encouragement of carpooling and utilization of public transportation among employees.</li><li style=\"border:0px solid rgb(227,227,227);box-sizing:border-box;margin:0px;padding-left:0.375em;display:block;min-height:28px\">Implementation of a telecommuting policy to reduce the carbon emissions associated with commuting.</li></ul></li><li style=\"border:0px solid rgb(227,227,227);box-sizing:border-box;margin-bottom:0px;margin-top:0px;padding-left:0.375em;display:block;min-height:28px\"><p style=\"border:0px solid rgb(227,227,227);box-sizing:border-box;margin:0px\">Sustainable Procurement:</p><ul style=\"border:0px solid rgb(227,227,227);box-sizing:border-box;list-style:disc;margin:0px 0px 0px 1rem;padding:0px;display:flex\"><li style=\"border:0px solid rgb(227,227,227);box-sizing:border-box;margin:0px;padding-left:0.375em;display:block;min-height:28px\">Prioritization of suppliers and vendors who demonstrate a commitment to sustainability in their operations.</li><li style=\"border:0px solid rgb(227,227,227);box-sizing:border-box;margin:0px;padding-left:0.375em;display:block;min-height:28px\">Evaluation of product packaging to minimize waste and opt for eco-friendly alternatives whenever possible.</li></ul></li><li style=\"border:0px solid rgb(227,227,227);box-sizing:border-box;margin-bottom:0px;margin-top:0px;padding-left:0.375em;display:block;min-height:28px\"><p style=\"border:0px solid rgb(227,227,227);box-sizing:border-box;margin:0px\">Education and Awareness:</p><ul style=\"border:0px solid rgb(227,227,227);box-sizing:border-box;list-style:disc;margin:0px 0px 0px 1rem;padding:0px;display:flex\"><li style=\"border:0px solid rgb(227,227,227);box-sizing:border-box;margin:0px;padding-left:0.375em;display:block;min-height:28px\">Organizing workshops and seminars to educate employees about the importance of sustainability and provide them with practical tips for incorporating eco-friendly practices into their daily routines.</li><li style=\"border:0px solid rgb(227,227,227);box-sizing:border-box;margin:0px;padding-left:0.375em;display:block;min-height:28px\">Regular communication and updates regarding the progress of our sustainability initiatives to keep employees engaged and motivated.</li></ul></li></ol><p style=\"border:0px solid rgb(227,227,227);box-sizing:border-box;margin:1.25em 0px;color:rgb(13,13,13);font-family:Söhne,ui-sans-serif,system-ui,-apple-system,&quot;Segoe UI&quot;,Roboto,Ubuntu,Cantarell,&quot;Noto Sans&quot;,sans-serif,&quot;Helvetica Neue&quot;,Arial,&quot;Apple Color Emoji&quot;,&quot;Segoe UI Emoji&quot;,&quot;Segoe UI Symbol&quot;,&quot;Noto Color Emoji&quot;;font-size:16px\">I believe that by implementing these initiatives, we can not only reduce our environmental impact but also enhance our corporate image and attract environmentally-conscious customers and partners. Additionally, adopting sustainable practices can lead to cost savings through reduced energy consumption and waste management expenses in the long run.</p><p style=\"border:0px solid rgb(227,227,227);box-sizing:border-box;margin:1.25em 0px;color:rgb(13,13,13);font-family:Söhne,ui-sans-serif,system-ui,-apple-system,&quot;Segoe UI&quot;,Roboto,Ubuntu,Cantarell,&quot;Noto Sans&quot;,sans-serif,&quot;Helvetica Neue&quot;,Arial,&quot;Apple Color Emoji&quot;,&quot;Segoe UI Emoji&quot;,&quot;Segoe UI Symbol&quot;,&quot;Noto Color Emoji&quot;;font-size:16px\">I am eager to discuss these proposals further and collaborate with relevant stakeholders to develop a detailed implementation plan. Together, I am confident that we can make meaningful strides towards building a more sustainable future for our company and the planet.</p><p style=\"border:0px solid rgb(227,227,227);box-sizing:border-box;margin:1.25em 0px;color:rgb(13,13,13);font-family:Söhne,ui-sans-serif,system-ui,-apple-system,&quot;Segoe UI&quot;,Roboto,Ubuntu,Cantarell,&quot;Noto Sans&quot;,sans-serif,&quot;Helvetica Neue&quot;,Arial,&quot;Apple Color Emoji&quot;,&quot;Segoe UI Emoji&quot;,&quot;Segoe UI Symbol&quot;,&quot;Noto Color Emoji&quot;;font-size:16px\">Thank you for considering these proposals. I look forward to your feedback and the opportunity to work together on this important initiative.</p><p style=\"border:0px solid rgb(227,227,227);box-sizing:border-box;margin:1.25em 0px;color:rgb(13,13,13);font-family:Söhne,ui-sans-serif,system-ui,-apple-system,&quot;Segoe UI&quot;,Roboto,Ubuntu,Cantarell,&quot;Noto Sans&quot;,sans-serif,&quot;Helvetica Neue&quot;,Arial,&quot;Apple Color Emoji&quot;,&quot;Segoe UI Emoji&quot;,&quot;Segoe UI Symbol&quot;,&quot;Noto Color Emoji&quot;;font-size:16px\">Best regards,</p><p style=\"border:0px solid rgb(227,227,227);box-sizing:border-box;margin:1.25em 0px 0px;color:rgb(13,13,13);font-family:Söhne,ui-sans-serif,system-ui,-apple-system,&quot;Segoe UI&quot;,Roboto,Ubuntu,Cantarell,&quot;Noto Sans&quot;,sans-serif,&quot;Helvetica Neue&quot;,Arial,&quot;Apple Color Emoji&quot;,&quot;Segoe UI Emoji&quot;,&quot;Segoe UI Symbol&quot;,&quot;Noto Color Emoji&quot;;font-size:16px\">[Your Name]\\r\\n[Your Position]\\r\\n[Your Contact Information]</p></div>\\r\\n', 'This is automated draft mail\\r\\n', 'This is automated draft mail\\n', 'This is automated draft mail\\n', '<!DOCTYPE html><html lang=\"en\"><head><meta name=\"format-detection\" content=\"email=no\"/><meta name=\"format-detection\" content=\"date=no\"/><style nonce=\"VJL7q3biZQConbF6GNozSg\">.awl a {color: #FFFFFF; text-decoration: none;} .abml a {color: #000000; font-family: Roboto-Medium,Helvetica,Arial,sans-serif; font-weight: bold; text-decoration: none;} .adgl a {color: rgba(0, 0, 0, 0.87); text-decoration: none;} .afal a {color: #b0b0b0; text-decoration: none;} @media screen and (min-width: 600px) {.v2sp {padding: 6px 30px 0px;} .v2rsp {padding: 0px 10px;}} @media screen and (min-width: 600px) {.mdv2rw {padding: 40px 40px;}} </style><link href=\"//fonts.googleapis.com/css?family=Google+Sans\" rel=\"stylesheet\" type=\"text/css\" nonce=\"VJL7q3biZQConbF6GNozSg\"/></head><body style=\"margin: 0; padding: 0;\" bgcolor=\"#FFFFFF\"><table width=\"100%\" height=\"100%\" style=\"min-width: 348px;\" border=\"0\" cellspacing=\"0\" cellpadding=\"0\" lang=\"en\"><tr height=\"32\" style=\"height: 32px;\"><td></td></tr><tr align=\"center\"><td><div itemscope itemtype=\"//schema.org/EmailMessage\"><div itemprop=\"action\" itemscope itemtype=\"//schema.org/ViewAction\"><link itemprop=\"url\" href=\"https://accounts.google.com/AccountChooser?Email=rutujamgupte@gmail.com&amp;continue=https://myaccount.google.com/alert/nt/1708796810000?rfn%3D127%26rfnc%3D1%26eid%3D4254849599651670286%26et%3D0\"/><meta itemprop=\"name\" content=\"Review Activity\"/></div></div><table border=\"0\" cellspacing=\"0\" cellpadding=\"0\" style=\"padding-bottom: 20px; max-width: 516px; min-width: 220px;\"><tr><td width=\"8\" style=\"width: 8px;\"></td><td><div style=\"border-style: solid; border-width: thin; border-color:#dadce0; border-radius: 8px; padding: 40px 20px;\" align=\"center\" class=\"mdv2rw\"><img src=\"https://www.gstatic.com/images/branding/googlelogo/2x/googlelogo_color_74x24dp.png\" width=\"74\" height=\"24\" aria-hidden=\"true\" style=\"margin-bottom: 16px;\" alt=\"Google\"><div style=\"font-family: &#39;Google Sans&#39;,Roboto,RobotoDraft,Helvetica,Arial,sans-serif;border-bottom: thin solid #dadce0; color: rgba(0,0,0,0.87); line-height: 32px; padding-bottom: 24px;text-align: center; word-break: break-word;\"><div style=\"font-size: 24px;\"><a>Google Auth Library</a> was granted access to your Google&nbsp;Account </div><table align=\"center\" style=\"margin-top:8px;\"><tr style=\"line-height: normal;\"><td align=\"right\" style=\"padding-right:8px;\"><img width=\"20\" height=\"20\" style=\"width: 20px; height: 20px; vertical-align: sub; border-radius: 50%;;\" src=\"https://lh3.googleusercontent.com/a/ACg8ocKC18b_w7ao7a3T2EV8qnGsFm-Z5dQ0mMeDtWDJLPeL=s96-c\" alt=\"\"></td><td><a style=\"font-family: &#39;Google Sans&#39;,Roboto,RobotoDraft,Helvetica,Arial,sans-serif;color: rgba(0,0,0,0.87); font-size: 14px; line-height: 20px;\">rutujamgupte@gmail.com</a></td></tr></table> </div><div style=\"font-family: Roboto-Regular,Helvetica,Arial,sans-serif; font-size: 14px; color: rgba(0,0,0,0.87); line-height: 20px;padding-top: 20px; text-align: left;\"><br>If you did not grant access, you should check this activity and secure your account.<div style=\"padding-top: 32px; text-align: center;\"><a href=\"https://accounts.google.com/AccountChooser?Email=rutujamgupte@gmail.com&amp;continue=https://myaccount.google.com/alert/nt/1708796810000?rfn%3D127%26rfnc%3D1%26eid%3D4254849599651670286%26et%3D0\" target=\"_blank\" link-id=\"main-button-link\" style=\"font-family: &#39;Google Sans&#39;,Roboto,RobotoDraft,Helvetica,Arial,sans-serif; line-height: 16px; color: #ffffff; font-weight: 400; text-decoration: none;font-size: 14px;display:inline-block;padding: 10px 24px;background-color: #4184F3; border-radius: 5px; min-width: 90px;\">Check activity</a></div></div><div style=\"padding-top: 20px; font-size: 12px; line-height: 16px; color: #5f6368; letter-spacing: 0.3px; text-align: center\">You can also see security activity at<br><a style=\"color: rgba(0, 0, 0, 0.87);text-decoration: inherit;\">https://myaccount.google.com/notifications</a></div></div><div style=\"text-align: left;\"><div style=\"font-family: Roboto-Regular,Helvetica,Arial,sans-serif;color: rgba(0,0,0,0.54); font-size: 11px; line-height: 18px; padding-top: 12px; text-align: center;\"><div>You received this email to let you know about important changes to your Google Account and services.</div><div style=\"direction: ltr;\">&copy; 2024 Google LLC, <a class=\"afal\" style=\"font-family: Roboto-Regular,Helvetica,Arial,sans-serif;color: rgba(0,0,0,0.54); font-size: 11px; line-height: 18px; padding-top: 12px; text-align: center;\">1600 Amphitheatre Parkway, Mountain View, CA 94043, USA</a></div></div></div></td><td width=\"8\" style=\"width: 8px;\"></td></tr></table></td></tr><tr height=\"32\" style=\"height: 32px;\"><td></td></tr></table></body></html>']\n"
     ]
    }
   ],
   "source": [
    "%run access_script.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "c9311caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import re\n",
    "import string\n",
    "import tqdm\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fcdb2b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cbaf1109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'wide', 'road', 'shimmered', 'in', 'the', 'hot', 'sun']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"The wide road shimmered in the hot sun\"\n",
    "tokens = list(sentence.lower().split())\n",
    "print((tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d6c6e03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<pad>': 0, 'the': 1, 'wide': 2, 'road': 3, 'shimmered': 4, 'in': 5, 'hot': 6, 'sun': 7}\n"
     ]
    }
   ],
   "source": [
    "vocab, index = {}, 1  # start indexing from 1\n",
    "vocab['<pad>'] = 0  # add a padding token\n",
    "for token in tokens:\n",
    "    if token not in vocab:\n",
    "        vocab[token] = index\n",
    "        index += 1\n",
    "vocab_size = len(vocab)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "850af1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<pad>', 1: 'the', 2: 'wide', 3: 'road', 4: 'shimmered', 5: 'in', 6: 'hot', 7: 'sun'}\n"
     ]
    }
   ],
   "source": [
    "inverse_vocab = {index: token for token, index in vocab.items()}\n",
    "print(inverse_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cbb1355d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 1, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "example_sequence = [vocab[word] for word in tokens]\n",
    "print(example_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f352b884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "window_size = 2\n",
    "positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
    "      example_sequence,\n",
    "      vocabulary_size=vocab_size,\n",
    "      window_size=window_size,\n",
    "      negative_samples=0)\n",
    "print(len(positive_skip_grams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "83531a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1): (in, the)\n",
      "(7, 1): (sun, the)\n",
      "(7, 6): (sun, hot)\n",
      "(1, 7): (the, sun)\n",
      "(2, 1): (wide, the)\n"
     ]
    }
   ],
   "source": [
    "for target, context in positive_skip_grams[:5]:\n",
    "    print(f\"({target}, {context}): ({inverse_vocab[target]}, {inverse_vocab[context]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f71703da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00315225 0.00315225 0.00547597 0.00741556 0.00912817 0.01068435\n",
      " 0.01212381 0.01347162 0.01474487 0.0159558 ]\n"
     ]
    }
   ],
   "source": [
    "sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(size=10)\n",
    "print(sampling_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bb532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get target and context words for one positive skip-gram.\n",
    "target_word, context_word = positive_skip_grams[0]\n",
    "\n",
    "# Set the number of negative samples per positive context.\n",
    "num_ns = 4\n",
    "\n",
    "context_class = tf.reshape(tf.constant(context_word, dtype=\"int64\"), (1, 1))\n",
    "negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "    true_classes=context_class,  # class that should be sampled as 'positive'\n",
    "    num_true=1,  # each positive skip-gram has 1 positive context class\n",
    "    num_sampled=num_ns,  # number of negative context words to sample\n",
    "    unique=True,  # all the negative samples should be unique\n",
    "    range_max=vocab_size,  # pick index of the samples from [0, vocab_size]\n",
    "    seed=SEED,  # seed for reproducibility\n",
    "    name=\"negative_sampling\"  # name of this operation\n",
    ")\n",
    "print(negative_sampling_candidates)\n",
    "print([inverse_vocab[index.numpy()] for index in negative_sampling_candidates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6903a519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates skip-gram pairs with negative sampling for a list of sequences\n",
    "# (int-encoded sentences) based on window size, number of negative samples\n",
    "# and vocabulary size.\n",
    "def generate_training_data(sequences, window_size, num_ns, vocab_size, seed):\n",
    "    # Elements of each training example are appended to these lists.\n",
    "    targets, contexts, labels = [], [], []\n",
    "\n",
    "    # Build the sampling table for `vocab_size` tokens.\n",
    "    sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(vocab_size)\n",
    "\n",
    "    # Iterate over all sequences (sentences) in the dataset.\n",
    "    for sequence in tqdm.tqdm(sequences):\n",
    "\n",
    "        # Generate positive skip-gram pairs for a sequence (sentence).\n",
    "        positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
    "                    sequence,\n",
    "                    vocabulary_size=vocab_size,\n",
    "                    sampling_table=sampling_table,\n",
    "                    window_size=window_size,\n",
    "                    negative_samples=0)\n",
    "\n",
    "        # Iterate over each positive skip-gram pair to produce training examples\n",
    "        # with a positive context word and negative samples.\n",
    "        for target_word, context_word in positive_skip_grams:\n",
    "            context_class = tf.expand_dims(\n",
    "                    tf.constant([context_word], dtype=\"int64\"), 1)\n",
    "            negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "                    true_classes=context_class,\n",
    "                    num_true=1,\n",
    "                    num_sampled=num_ns,\n",
    "                    unique=True,\n",
    "                    range_max=vocab_size,\n",
    "                    seed=seed,\n",
    "                    name=\"negative_sampling\")\n",
    "\n",
    "            # Build context and label vectors (for one target word)\n",
    "            context = tf.concat([tf.squeeze(context_class,1), negative_sampling_candidates], 0)\n",
    "            label = tf.constant([1] + [0]*num_ns, dtype=\"int64\")\n",
    "\n",
    "            # Append each element from the training example to global lists.\n",
    "            targets.append(target_word)\n",
    "            contexts.append(context)\n",
    "            labels.append(label)\n",
    "\n",
    "    return targets, contexts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ccc4d560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
      "1115394/1115394 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a2453c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n"
     ]
    }
   ],
   "source": [
    "with open(path_to_file) as f:\n",
    "    lines = f.read().splitlines()\n",
    "for line in lines[:20]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "768b4bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ds = tf.data.TextLineDataset(path_to_file).filter(lambda x: tf.cast(tf.strings.length(x), bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1e499226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, create a custom standardization function to lowercase the text and\n",
    "# remove punctuation.\n",
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    return tf.strings.regex_replace(lowercase,\n",
    "                                  '[%s]' % re.escape(string.punctuation), '')\n",
    "\n",
    "\n",
    "# Define the vocabulary size and the number of words in a sequence.\n",
    "vocab_size = 512\n",
    "sequence_length = 10\n",
    "\n",
    "# Use the `TextVectorization` layer to normalize, split, and map strings to\n",
    "# integers. Set the `output_sequence_length` length to pad all samples to the\n",
    "# same length.\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0e2f16df",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer.adapt(text_ds.batch(1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f1c22a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', 'the', 'and', 'to', 'i', 'of', 'you', 'my', 'a', 'that', 'in', 'is', 'not', 'for', 'with', 'me', 'it', 'be', 'your']\n"
     ]
    }
   ],
   "source": [
    "# Save the created vocabulary for reference.\n",
    "inverse_vocab = vectorize_layer.get_vocabulary()\n",
    "print(inverse_vocab[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e306de38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the data in text_ds.\n",
    "text_vector_ds = text_ds.batch(1024).prefetch(AUTOTUNE).map(vectorize_layer).unbatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "da38f817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32777\n"
     ]
    }
   ],
   "source": [
    "sequences = list(text_vector_ds.as_numpy_iterator())\n",
    "print(len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d6767161",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 32777/32777 [00:23<00:00, 1411.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "targets.shape: (24867,)\n",
      "contexts.shape: (24867, 5)\n",
      "labels.shape: (24867, 5)\n"
     ]
    }
   ],
   "source": [
    "targets, contexts, labels = generate_training_data(\n",
    "    sequences=sequences,\n",
    "    window_size=2,\n",
    "    num_ns=4,\n",
    "    vocab_size=vocab_size,\n",
    "    seed=SEED)\n",
    "\n",
    "targets = np.array(targets)\n",
    "contexts = np.array(contexts)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print('\\n')\n",
    "print(f\"targets.shape: {targets.shape}\")\n",
    "print(f\"contexts.shape: {contexts.shape}\")\n",
    "print(f\"labels.shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "57474956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_BatchDataset element_spec=((TensorSpec(shape=(1024,), dtype=tf.int64, name=None), TensorSpec(shape=(1024, 5), dtype=tf.int64, name=None)), TensorSpec(shape=(1024, 5), dtype=tf.int64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 1024\n",
    "BUFFER_SIZE = 10000\n",
    "dataset = tf.data.Dataset.from_tensor_slices(((targets, contexts), labels))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ba6d2d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_PrefetchDataset element_spec=((TensorSpec(shape=(1024,), dtype=tf.int64, name=None), TensorSpec(shape=(1024, 5), dtype=tf.int64, name=None)), TensorSpec(shape=(1024, 5), dtype=tf.int64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f087039",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4571a5e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8f5291",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2884b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2fad3f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(Word2Vec, self).__init__()\n",
    "        self.target_embedding = layers.Embedding(vocab_size,\n",
    "                                          embedding_dim,\n",
    "                                          input_length=1,\n",
    "                                          name=\"w2v_embedding\")\n",
    "        self.context_embedding = layers.Embedding(vocab_size,\n",
    "                                               embedding_dim,\n",
    "                                               input_length=num_ns+1)\n",
    "\n",
    "    def call(self, pair):\n",
    "        target, context = pair\n",
    "        # target: (batch, dummy?)  # The dummy axis doesn't exist in TF2.7+\n",
    "        # context: (batch, context)\n",
    "        if len(target.shape) == 2:\n",
    "            target = tf.squeeze(target, axis=1)\n",
    "        # target: (batch,)\n",
    "        word_emb = self.target_embedding(target)\n",
    "        # word_emb: (batch, embed)\n",
    "        context_emb = self.context_embedding(context)\n",
    "        # context_emb: (batch, context, embed)\n",
    "        dots = tf.einsum('be,bce->bc', word_emb, context_emb)\n",
    "        # dots: (batch, context)\n",
    "        return dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "da55bfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(x_logit, y_true):\n",
    "      return tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "80e69b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 128\n",
    "word2vec = Word2Vec(vocab_size, embedding_dim)\n",
    "word2vec.compile(optimizer='adam',\n",
    "                 loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "fe7f8663",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "1cf0c62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "24/24 [==============================] - 1s 14ms/step - loss: 1.6065 - accuracy: 0.2921\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.5876 - accuracy: 0.4992\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.5476 - accuracy: 0.5324\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 1.4862 - accuracy: 0.5136\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.4271 - accuracy: 0.4951\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 1.3865 - accuracy: 0.4910\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.3571 - accuracy: 0.4990\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.3307 - accuracy: 0.5108\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.3053 - accuracy: 0.5241\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.2802 - accuracy: 0.5358\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.2556 - accuracy: 0.5471\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.2314 - accuracy: 0.5590\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.2076 - accuracy: 0.5701\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.1842 - accuracy: 0.5810\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.1611 - accuracy: 0.5915\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.1383 - accuracy: 0.6013\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.1158 - accuracy: 0.6093\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.0937 - accuracy: 0.6190\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.0720 - accuracy: 0.6292\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.0507 - accuracy: 0.6391\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x19374fe8dd0>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.fit(dataset, epochs=20, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "92a8ae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = word2vec.get_layer('w2v_embedding').get_weights()[0]\n",
    "vocab = vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4534cac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for index, word in enumerate(vocab):\n",
    "    if index == 0:\n",
    "        continue  # skip 0, it's padding.\n",
    "    vec = weights[index]\n",
    "    out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "    out_m.write(word + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c497ec42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03407152, -0.02948897,  0.02585742, ..., -0.01414828,\n",
       "         0.00647162, -0.03313811],\n",
       "       [ 0.03657696, -0.08933467, -0.13787562, ..., -0.0943652 ,\n",
       "         0.11502133, -0.01733635],\n",
       "       [-0.08532259,  0.27981082,  0.17016403, ...,  0.11697411,\n",
       "        -0.00199034,  0.0460463 ],\n",
       "       ...,\n",
       "       [ 0.14061852, -0.13591178,  0.2515117 , ..., -0.15124977,\n",
       "         0.02733884,  0.00854242],\n",
       "       [ 0.08953336,  0.21459836,  0.11056946, ...,  0.0107081 ,\n",
       "         0.04126754, -0.06935227],\n",
       "       [-0.18723059,  0.17448036,  0.17133783, ...,  0.02400639,\n",
       "         0.14721987, -0.04866942]], dtype=float32)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "3a9af281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "4b9c9cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 128)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c1c87a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "4ef39dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'the',\n",
       " 'and',\n",
       " 'to',\n",
       " 'i',\n",
       " 'of',\n",
       " 'you',\n",
       " 'my',\n",
       " 'a',\n",
       " 'that',\n",
       " 'in',\n",
       " 'is',\n",
       " 'not',\n",
       " 'for',\n",
       " 'with',\n",
       " 'me',\n",
       " 'it',\n",
       " 'be',\n",
       " 'your',\n",
       " 'his',\n",
       " 'this',\n",
       " 'but',\n",
       " 'he',\n",
       " 'have',\n",
       " 'as',\n",
       " 'thou',\n",
       " 'him',\n",
       " 'so',\n",
       " 'what',\n",
       " 'thy',\n",
       " 'will',\n",
       " 'no',\n",
       " 'by',\n",
       " 'all',\n",
       " 'king',\n",
       " 'we',\n",
       " 'shall',\n",
       " 'her',\n",
       " 'if',\n",
       " 'our',\n",
       " 'are',\n",
       " 'do',\n",
       " 'thee',\n",
       " 'now',\n",
       " 'lord',\n",
       " 'good',\n",
       " 'on',\n",
       " 'o',\n",
       " 'come',\n",
       " 'from',\n",
       " 'sir',\n",
       " 'or',\n",
       " 'which',\n",
       " 'more',\n",
       " 'then',\n",
       " 'well',\n",
       " 'at',\n",
       " 'would',\n",
       " 'was',\n",
       " 'they',\n",
       " 'how',\n",
       " 'here',\n",
       " 'she',\n",
       " 'than',\n",
       " 'their',\n",
       " 'them',\n",
       " 'ill',\n",
       " 'duke',\n",
       " 'am',\n",
       " 'hath',\n",
       " 'say',\n",
       " 'let',\n",
       " 'when',\n",
       " 'one',\n",
       " 'go',\n",
       " 'were',\n",
       " 'love',\n",
       " 'may',\n",
       " 'us',\n",
       " 'make',\n",
       " 'upon',\n",
       " 'yet',\n",
       " 'richard',\n",
       " 'like',\n",
       " 'there',\n",
       " 'must',\n",
       " 'should',\n",
       " 'an',\n",
       " 'first',\n",
       " 'why',\n",
       " 'queen',\n",
       " 'had',\n",
       " 'know',\n",
       " 'man',\n",
       " 'did',\n",
       " 'tis',\n",
       " 'where',\n",
       " 'see',\n",
       " 'some',\n",
       " 'too',\n",
       " 'death',\n",
       " 'give',\n",
       " 'who',\n",
       " 'these',\n",
       " 'take',\n",
       " 'speak',\n",
       " 'edward',\n",
       " 'york',\n",
       " 'mine',\n",
       " 'such',\n",
       " 'up',\n",
       " 'out',\n",
       " 'henry',\n",
       " 'romeo',\n",
       " 'can',\n",
       " 'father',\n",
       " 'tell',\n",
       " 'time',\n",
       " 'gloucester',\n",
       " 'most',\n",
       " 'lady',\n",
       " 'son',\n",
       " 'nor',\n",
       " 'vincentio',\n",
       " 'hear',\n",
       " 'life',\n",
       " 'god',\n",
       " 'made',\n",
       " 'art',\n",
       " 'warwick',\n",
       " 'think',\n",
       " 'much',\n",
       " 'heart',\n",
       " 'never',\n",
       " 'doth',\n",
       " 'brother',\n",
       " 'ay',\n",
       " 'before',\n",
       " 'true',\n",
       " 'both',\n",
       " 'thus',\n",
       " 'cannot',\n",
       " 'petruchio',\n",
       " 'any',\n",
       " 'being',\n",
       " 'away',\n",
       " 'blood',\n",
       " 'name',\n",
       " 'fair',\n",
       " 'coriolanus',\n",
       " 'been',\n",
       " 'noble',\n",
       " 'men',\n",
       " 'menenius',\n",
       " 'look',\n",
       " 'again',\n",
       " 'very',\n",
       " 'hand',\n",
       " 'day',\n",
       " 'pray',\n",
       " 'own',\n",
       " 'juliet',\n",
       " 'done',\n",
       " 'sweet',\n",
       " 'second',\n",
       " 'myself',\n",
       " 'therefore',\n",
       " 'leave',\n",
       " 'great',\n",
       " 'against',\n",
       " 'though',\n",
       " 'poor',\n",
       " 'honour',\n",
       " 'down',\n",
       " 'prince',\n",
       " 'hast',\n",
       " 'way',\n",
       " 'angelo',\n",
       " 'fear',\n",
       " 'old',\n",
       " 'nay',\n",
       " 'heaven',\n",
       " 'clarence',\n",
       " 'till',\n",
       " 'call',\n",
       " 'eyes',\n",
       " 'world',\n",
       " 'stay',\n",
       " 'live',\n",
       " 'stand',\n",
       " 'nurse',\n",
       " 'grace',\n",
       " 'many',\n",
       " 'comes',\n",
       " 'ever',\n",
       " 'even',\n",
       " 'wife',\n",
       " 'nothing',\n",
       " 'iii',\n",
       " 'die',\n",
       " 'dead',\n",
       " 'whose',\n",
       " 'bear',\n",
       " 'night',\n",
       " 'other',\n",
       " 'isabella',\n",
       " 'bolingbroke',\n",
       " 'friends',\n",
       " 'leontes',\n",
       " 'head',\n",
       " 'friar',\n",
       " 'peace',\n",
       " 'buckingham',\n",
       " 'unto',\n",
       " 'those',\n",
       " 'better',\n",
       " 'lords',\n",
       " 'word',\n",
       " 'off',\n",
       " 'gone',\n",
       " 'tranio',\n",
       " 'two',\n",
       " 'mother',\n",
       " 'hence',\n",
       " 'marcius',\n",
       " 'house',\n",
       " 'still',\n",
       " 'since',\n",
       " 'news',\n",
       " 'lucio',\n",
       " 'could',\n",
       " 'sicinius',\n",
       " 'master',\n",
       " 'little',\n",
       " 'gentleman',\n",
       " 'daughter',\n",
       " 'soul',\n",
       " 'thing',\n",
       " 'put',\n",
       " 'once',\n",
       " 'whom',\n",
       " 'margaret',\n",
       " 'set',\n",
       " 'long',\n",
       " 'himself',\n",
       " 'face',\n",
       " 'camillo',\n",
       " 'words',\n",
       " 'thine',\n",
       " 'iv',\n",
       " 'ere',\n",
       " 'else',\n",
       " 'elizabeth',\n",
       " 'capulet',\n",
       " 'none',\n",
       " 'katharina',\n",
       " 'rest',\n",
       " 'might',\n",
       " 'madam',\n",
       " 'gods',\n",
       " 'crown',\n",
       " 'best',\n",
       " 'young',\n",
       " 'power',\n",
       " 'pardon',\n",
       " 'tongue',\n",
       " 'dear',\n",
       " 'part',\n",
       " 'farewell',\n",
       " 'citizen',\n",
       " 'vi',\n",
       " 'bring',\n",
       " 'keep',\n",
       " 'ii',\n",
       " 'hope',\n",
       " 'gentle',\n",
       " 'right',\n",
       " 'hastings',\n",
       " 'said',\n",
       " 'lucentio',\n",
       " 'find',\n",
       " 'every',\n",
       " 'hortensio',\n",
       " 'forth',\n",
       " 'came',\n",
       " 'bid',\n",
       " 'home',\n",
       " 'hands',\n",
       " 'earth',\n",
       " 'welcome',\n",
       " 'lets',\n",
       " 'into',\n",
       " 'brutus',\n",
       " 'hold',\n",
       " 'dost',\n",
       " 'cause',\n",
       " 'tears',\n",
       " 'boy',\n",
       " 'baptista',\n",
       " 'back',\n",
       " 'about',\n",
       " 'rome',\n",
       " 'please',\n",
       " 'thats',\n",
       " 'provost',\n",
       " 'mistress',\n",
       " 'people',\n",
       " 'makes',\n",
       " 'help',\n",
       " 'indeed',\n",
       " 'heard',\n",
       " 'full',\n",
       " 'cousin',\n",
       " 'thought',\n",
       " 'show',\n",
       " 'after',\n",
       " 'wilt',\n",
       " 'place',\n",
       " 'mind',\n",
       " 'has',\n",
       " 'grumio',\n",
       " 'escalus',\n",
       " 'cominius',\n",
       " 'pompey',\n",
       " 'marry',\n",
       " 'husband',\n",
       " 'whats',\n",
       " 'friend',\n",
       " 'state',\n",
       " 'shame',\n",
       " 'mean',\n",
       " 'within',\n",
       " 'gremio',\n",
       " 'while',\n",
       " 'servant',\n",
       " 'clifford',\n",
       " 'only',\n",
       " 'hither',\n",
       " 'hes',\n",
       " 'fathers',\n",
       " 'gracious',\n",
       " 'aufidius',\n",
       " 'royal',\n",
       " 'rather',\n",
       " 'prove',\n",
       " 'northumberland',\n",
       " 'last',\n",
       " 'far',\n",
       " 'eye',\n",
       " 'duchess',\n",
       " 'answer',\n",
       " 'thousand',\n",
       " 'mercutio',\n",
       " 'lie',\n",
       " 'third',\n",
       " 'another',\n",
       " 'paulina',\n",
       " 'meet',\n",
       " 'claudio',\n",
       " 'murderer',\n",
       " 'shalt',\n",
       " 'lay',\n",
       " 'child',\n",
       " 'use',\n",
       " 'sorrow',\n",
       " 'lies',\n",
       " 'joy',\n",
       " 'comfort',\n",
       " 'beseech',\n",
       " 'tomorrow',\n",
       " 'grief',\n",
       " 'benvolio',\n",
       " 'war',\n",
       " 'sun',\n",
       " 'polixenes',\n",
       " 'less',\n",
       " 'kings',\n",
       " 'autolycus',\n",
       " 'years',\n",
       " 'hour',\n",
       " 'happy',\n",
       " 'fortune',\n",
       " 'fellow',\n",
       " 'end',\n",
       " 'thank',\n",
       " 'montague',\n",
       " 'holy',\n",
       " 'business',\n",
       " 'things',\n",
       " 'matter',\n",
       " 'hate',\n",
       " 'grave',\n",
       " 'faith',\n",
       " 'enough',\n",
       " 'arms',\n",
       " 'truth',\n",
       " 'prospero',\n",
       " 'lives',\n",
       " 'light',\n",
       " 'clown',\n",
       " 'bed',\n",
       " 'without',\n",
       " 'three',\n",
       " 'save',\n",
       " 'pity',\n",
       " 'fall',\n",
       " 'body',\n",
       " 'nature',\n",
       " 'kind',\n",
       " 'get',\n",
       " 'tybalt',\n",
       " 'turn',\n",
       " 'theres',\n",
       " 'swear',\n",
       " 'send',\n",
       " 'laurence',\n",
       " 'kate',\n",
       " 'days',\n",
       " 'saw',\n",
       " 'hell',\n",
       " 'fight',\n",
       " 'false',\n",
       " 'bianca',\n",
       " 'believe',\n",
       " 'ah',\n",
       " 'law',\n",
       " 'follow',\n",
       " 'yourself',\n",
       " 'yours',\n",
       " 'villain',\n",
       " 'uncle',\n",
       " 'present',\n",
       " 'means',\n",
       " 'looks',\n",
       " 'does',\n",
       " 'volumnia',\n",
       " 'talk',\n",
       " 'sleep',\n",
       " 'neer',\n",
       " 'left',\n",
       " 'foul',\n",
       " 'bloody',\n",
       " 'aumerle',\n",
       " 'anne',\n",
       " 'city',\n",
       " 'worthy',\n",
       " 'woman',\n",
       " 'told',\n",
       " 'servingman',\n",
       " 'proud',\n",
       " 'need',\n",
       " 'mercy',\n",
       " 'land',\n",
       " 'hearts',\n",
       " 'brothers',\n",
       " 'wish',\n",
       " 'sound',\n",
       " 'sit',\n",
       " 'shepherd',\n",
       " 'sea',\n",
       " 'play',\n",
       " 'messenger',\n",
       " 'together',\n",
       " 'thyself',\n",
       " 'sword',\n",
       " 'justice',\n",
       " 'high',\n",
       " 'gaunt',\n",
       " 'doubt',\n",
       " 'breath',\n",
       " 'because',\n",
       " 'woe',\n",
       " 'through',\n",
       " 'majesty',\n",
       " 'john',\n",
       " 'horse',\n",
       " 'fire',\n",
       " 'either',\n",
       " 'biondello',\n",
       " 'under',\n",
       " 'sovereign',\n",
       " 'sister',\n",
       " 'seen',\n",
       " 'paris',\n",
       " 'heres',\n",
       " 'children',\n",
       " 'catesby',\n",
       " 'break',\n",
       " 'maid',\n",
       " 'heavy',\n",
       " 'twas',\n",
       " 'times',\n",
       " 'signior',\n",
       " 'lost',\n",
       " 'gentlemen',\n",
       " 'content',\n",
       " 'care',\n",
       " 'wrong',\n",
       " 'traitor',\n",
       " 'says',\n",
       " 'ready',\n",
       " 'purpose',\n",
       " 'oath',\n",
       " 'norfolk',\n",
       " 'loves',\n",
       " 'kill',\n",
       " 'haste',\n",
       " 'fly',\n",
       " 'florizel',\n",
       " 'edwards',\n",
       " 'ears']"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5117189d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in lines:\n",
    "    w = line.split(\" \")\n",
    "    for word in w:\n",
    "        if word.strip().lower() in words:\n",
    "            words[word.strip().lower()] += 1\n",
    "        else:\n",
    "            words[word.strip().lower()] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "af0d5f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27974"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "939410b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'session': 4,\n",
       " 'First': 235,\n",
       " 'Citizen:': 98,\n",
       " 'Before': 31,\n",
       " 'we': 2338,\n",
       " 'proceed': 32,\n",
       " 'any': 545,\n",
       " 'further,': 12,\n",
       " 'hear': 562,\n",
       " 'me': 3347,\n",
       " 'speak.': 114,\n",
       " '': 21723,\n",
       " 'All:': 19,\n",
       " 'Speak,': 6,\n",
       " 'You': 319,\n",
       " 'are': 2146,\n",
       " 'all': 2168,\n",
       " 'resolved': 29,\n",
       " 'rather': 192,\n",
       " 'to': 13369,\n",
       " 'die': 190,\n",
       " 'than': 1297,\n",
       " 'famish?': 3,\n",
       " 'Resolved.': 1,\n",
       " 'resolved.': 5,\n",
       " 'First,': 20,\n",
       " 'you': 7028,\n",
       " 'know': 857,\n",
       " 'Caius': 14,\n",
       " 'Marcius': 30,\n",
       " 'is': 5694,\n",
       " 'chief': 18,\n",
       " 'enemy': 54,\n",
       " 'the': 17995,\n",
       " 'people.': 36,\n",
       " 'We': 182,\n",
       " \"know't,\": 3,\n",
       " \"know't.\": 9,\n",
       " 'Let': 125,\n",
       " 'us': 786,\n",
       " 'kill': 129,\n",
       " 'him,': 508,\n",
       " 'and': 14636,\n",
       " \"we'll\": 188,\n",
       " 'have': 4052,\n",
       " 'corn': 20,\n",
       " 'at': 1592,\n",
       " 'our': 2274,\n",
       " 'own': 411,\n",
       " 'price.': 3,\n",
       " \"Is't\": 12,\n",
       " 'a': 8560,\n",
       " 'verdict?': 3,\n",
       " 'No': 94,\n",
       " 'more': 1313,\n",
       " 'talking': 12,\n",
       " \"on't;\": 6,\n",
       " 'let': 1186,\n",
       " 'it': 3919,\n",
       " 'be': 4683,\n",
       " 'done:': 33,\n",
       " 'away,': 73,\n",
       " 'away!': 62,\n",
       " 'Second': 149,\n",
       " 'One': 45,\n",
       " 'word,': 69,\n",
       " 'good': 1704,\n",
       " 'citizens.': 6,\n",
       " 'accounted': 6,\n",
       " 'poor': 425,\n",
       " 'citizens,': 18,\n",
       " 'patricians': 12,\n",
       " 'good.': 39,\n",
       " 'What': 379,\n",
       " 'authority': 20,\n",
       " 'surfeits': 3,\n",
       " 'on': 1667,\n",
       " 'would': 1484,\n",
       " 'relieve': 9,\n",
       " 'us:': 42,\n",
       " 'if': 2074,\n",
       " 'they': 1460,\n",
       " 'yield': 108,\n",
       " 'but': 3669,\n",
       " 'superfluity,': 3,\n",
       " 'while': 160,\n",
       " 'were': 1113,\n",
       " 'wholesome,': 3,\n",
       " 'might': 291,\n",
       " 'guess': 26,\n",
       " 'relieved': 3,\n",
       " 'humanely;': 3,\n",
       " 'think': 515,\n",
       " 'too': 605,\n",
       " 'dear:': 6,\n",
       " 'leanness': 6,\n",
       " 'that': 6666,\n",
       " 'afflicts': 3,\n",
       " 'us,': 165,\n",
       " 'object': 21,\n",
       " 'of': 10717,\n",
       " 'misery,': 12,\n",
       " 'as': 3833,\n",
       " 'an': 1036,\n",
       " 'inventory': 3,\n",
       " 'particularise': 3,\n",
       " 'their': 1398,\n",
       " 'abundance;': 3,\n",
       " 'sufferance': 6,\n",
       " 'gain': 27,\n",
       " 'them': 954,\n",
       " 'revenge': 69,\n",
       " 'this': 3812,\n",
       " 'with': 5164,\n",
       " 'pikes,': 3,\n",
       " 'ere': 302,\n",
       " 'become': 102,\n",
       " 'rakes:': 3,\n",
       " 'for': 5051,\n",
       " 'gods': 120,\n",
       " 'I': 4403,\n",
       " 'speak': 518,\n",
       " 'in': 6697,\n",
       " 'hunger': 6,\n",
       " 'bread,': 3,\n",
       " 'not': 5113,\n",
       " 'thirst': 9,\n",
       " 'revenge.': 12,\n",
       " 'Would': 67,\n",
       " 'especially': 11,\n",
       " 'against': 438,\n",
       " 'Marcius?': 5,\n",
       " 'Against': 42,\n",
       " 'him': 2140,\n",
       " 'first:': 21,\n",
       " \"he's\": 210,\n",
       " 'very': 515,\n",
       " 'dog': 33,\n",
       " 'commonalty.': 3,\n",
       " 'Consider': 4,\n",
       " 'what': 2429,\n",
       " 'services': 27,\n",
       " 'he': 3971,\n",
       " 'has': 230,\n",
       " 'done': 227,\n",
       " 'his': 4433,\n",
       " 'country?': 3,\n",
       " 'Very': 13,\n",
       " 'well;': 79,\n",
       " 'could': 327,\n",
       " 'content': 88,\n",
       " 'give': 799,\n",
       " 'report': 98,\n",
       " 'fort,': 3,\n",
       " 'pays': 12,\n",
       " 'himself': 173,\n",
       " 'being': 515,\n",
       " 'proud.': 9,\n",
       " 'Nay,': 117,\n",
       " 'maliciously.': 3,\n",
       " 'say': 818,\n",
       " 'unto': 354,\n",
       " 'you,': 1074,\n",
       " 'hath': 1259,\n",
       " 'famously,': 3,\n",
       " 'did': 869,\n",
       " 'end:': 12,\n",
       " 'though': 414,\n",
       " 'soft-conscienced': 3,\n",
       " 'men': 339,\n",
       " 'can': 721,\n",
       " 'was': 1435,\n",
       " 'country': 42,\n",
       " 'please': 218,\n",
       " 'mother': 156,\n",
       " 'partly': 29,\n",
       " 'proud;': 9,\n",
       " 'which': 1376,\n",
       " 'is,': 188,\n",
       " 'even': 334,\n",
       " 'till': 392,\n",
       " 'altitude': 3,\n",
       " 'virtue.': 9,\n",
       " 'cannot': 525,\n",
       " 'help': 172,\n",
       " 'nature,': 53,\n",
       " 'account': 32,\n",
       " 'vice': 27,\n",
       " 'him.': 462,\n",
       " 'must': 1045,\n",
       " 'no': 1952,\n",
       " 'way': 273,\n",
       " 'covetous.': 3,\n",
       " 'If': 296,\n",
       " 'not,': 384,\n",
       " 'need': 137,\n",
       " 'barren': 24,\n",
       " 'accusations;': 3,\n",
       " 'faults,': 21,\n",
       " 'surplus,': 3,\n",
       " 'tire': 11,\n",
       " 'repetition.': 3,\n",
       " 'shouts': 6,\n",
       " 'these?': 9,\n",
       " 'The': 842,\n",
       " 'other': 330,\n",
       " 'side': 51,\n",
       " \"o'\": 328,\n",
       " 'city': 99,\n",
       " 'risen:': 3,\n",
       " 'why': 325,\n",
       " 'stay': 242,\n",
       " 'prating': 12,\n",
       " 'here?': 99,\n",
       " 'Capitol!': 2,\n",
       " 'Come,': 152,\n",
       " 'come.': 108,\n",
       " 'Soft!': 3,\n",
       " 'who': 653,\n",
       " 'comes': 339,\n",
       " 'Worthy': 11,\n",
       " 'Menenius': 3,\n",
       " 'Agrippa;': 1,\n",
       " 'one': 1050,\n",
       " 'always': 50,\n",
       " 'loved': 84,\n",
       " \"He's\": 27,\n",
       " 'honest': 93,\n",
       " 'enough:': 9,\n",
       " 'rest': 164,\n",
       " 'so!': 18,\n",
       " 'MENENIUS:': 162,\n",
       " \"work's,\": 3,\n",
       " 'my': 8905,\n",
       " 'countrymen,': 9,\n",
       " 'hand?': 9,\n",
       " 'where': 772,\n",
       " 'go': 742,\n",
       " 'With': 236,\n",
       " 'bats': 6,\n",
       " 'clubs?': 3,\n",
       " 'matter?': 36,\n",
       " 'speak,': 111,\n",
       " 'pray': 326,\n",
       " 'you.': 444,\n",
       " 'Our': 84,\n",
       " 'business': 99,\n",
       " 'unknown': 23,\n",
       " 'senate;': 3,\n",
       " 'had': 950,\n",
       " 'inkling': 3,\n",
       " 'fortnight': 9,\n",
       " 'intend': 38,\n",
       " 'do,': 115,\n",
       " 'now': 1089,\n",
       " 'show': 219,\n",
       " \"'em\": 21,\n",
       " 'deeds.': 6,\n",
       " 'They': 85,\n",
       " 'suitors': 14,\n",
       " 'strong': 74,\n",
       " 'breaths:': 3,\n",
       " 'shall': 2331,\n",
       " 'arms': 75,\n",
       " 'too.': 69,\n",
       " 'Why,': 176,\n",
       " 'masters,': 35,\n",
       " 'friends,': 123,\n",
       " 'mine': 592,\n",
       " 'neighbours,': 8,\n",
       " 'Will': 90,\n",
       " 'undo': 12,\n",
       " 'yourselves?': 6,\n",
       " 'cannot,': 33,\n",
       " 'sir,': 921,\n",
       " 'undone': 18,\n",
       " 'already.': 18,\n",
       " 'tell': 690,\n",
       " 'most': 696,\n",
       " 'charitable': 9,\n",
       " 'care': 99,\n",
       " 'Have': 106,\n",
       " 'For': 453,\n",
       " 'your': 4853,\n",
       " 'wants,': 6,\n",
       " 'Your': 187,\n",
       " 'suffering': 12,\n",
       " 'dearth,': 6,\n",
       " 'may': 1080,\n",
       " 'well': 677,\n",
       " 'Strike': 6,\n",
       " 'heaven': 253,\n",
       " 'staves': 6,\n",
       " 'lift': 25,\n",
       " 'Roman': 8,\n",
       " 'state,': 72,\n",
       " 'whose': 363,\n",
       " 'course': 57,\n",
       " 'will': 2754,\n",
       " 'takes,': 3,\n",
       " 'cracking': 15,\n",
       " 'ten': 102,\n",
       " 'thousand': 213,\n",
       " 'curbs': 9,\n",
       " 'Of': 232,\n",
       " 'link': 9,\n",
       " 'asunder': 3,\n",
       " 'ever': 358,\n",
       " 'Appear': 5,\n",
       " 'impediment.': 3,\n",
       " 'gods,': 27,\n",
       " 'patricians,': 12,\n",
       " 'make': 1127,\n",
       " 'it,': 387,\n",
       " 'knees': 39,\n",
       " 'them,': 168,\n",
       " 'arms,': 44,\n",
       " 'help.': 15,\n",
       " 'Alack,': 14,\n",
       " 'transported': 12,\n",
       " 'by': 2456,\n",
       " 'calamity': 6,\n",
       " 'Thither': 3,\n",
       " 'attends': 3,\n",
       " 'slander': 31,\n",
       " 'helms': 3,\n",
       " 'like': 1035,\n",
       " 'fathers,': 12,\n",
       " 'When': 153,\n",
       " 'curse': 71,\n",
       " 'enemies.': 27,\n",
       " 'Care': 3,\n",
       " 'us!': 27,\n",
       " 'True,': 9,\n",
       " 'indeed!': 6,\n",
       " \"ne'er\": 169,\n",
       " 'cared': 3,\n",
       " 'yet:': 12,\n",
       " 'suffer': 42,\n",
       " 'famish,': 3,\n",
       " 'store-houses': 3,\n",
       " 'crammed': 3,\n",
       " 'grain;': 3,\n",
       " 'edicts': 3,\n",
       " 'usury,': 3,\n",
       " 'support': 12,\n",
       " 'usurers;': 3,\n",
       " 'repeal': 5,\n",
       " 'daily': 27,\n",
       " 'wholesome': 24,\n",
       " 'act': 48,\n",
       " 'established': 3,\n",
       " 'rich,': 21,\n",
       " 'provide': 20,\n",
       " 'piercing': 20,\n",
       " 'statutes': 15,\n",
       " 'daily,': 3,\n",
       " 'chain': 9,\n",
       " 'up': 583,\n",
       " 'restrain': 3,\n",
       " 'poor.': 3,\n",
       " 'wars': 53,\n",
       " 'eat': 30,\n",
       " 'up,': 133,\n",
       " 'will;': 27,\n",
       " \"there's\": 162,\n",
       " 'love': 731,\n",
       " 'bear': 348,\n",
       " 'us.': 126,\n",
       " 'Either': 19,\n",
       " 'Confess': 4,\n",
       " 'yourselves': 24,\n",
       " 'wondrous': 26,\n",
       " 'malicious,': 3,\n",
       " 'Or': 163,\n",
       " 'accused': 21,\n",
       " 'folly.': 6,\n",
       " 'A': 365,\n",
       " 'pretty': 77,\n",
       " 'tale:': 15,\n",
       " 'heard': 230,\n",
       " 'it;': 99,\n",
       " 'But,': 69,\n",
       " 'since': 286,\n",
       " 'serves': 30,\n",
       " 'purpose,': 24,\n",
       " 'venture': 15,\n",
       " 'To': 800,\n",
       " 'stale': 15,\n",
       " \"'t\": 33,\n",
       " 'little': 310,\n",
       " 'more.': 99,\n",
       " 'Well,': 92,\n",
       " \"I'll\": 425,\n",
       " 'sir:': 81,\n",
       " 'yet': 877,\n",
       " 'fob': 3,\n",
       " 'off': 239,\n",
       " 'disgrace': 18,\n",
       " 'but,': 231,\n",
       " 'deliver.': 3,\n",
       " 'There': 80,\n",
       " 'time': 540,\n",
       " 'when': 1098,\n",
       " \"body's\": 30,\n",
       " 'members': 6,\n",
       " \"Rebell'd\": 1,\n",
       " 'belly,': 12,\n",
       " 'thus': 393,\n",
       " 'it:': 102,\n",
       " 'That': 615,\n",
       " 'only': 197,\n",
       " 'gulf': 12,\n",
       " 'remain': 44,\n",
       " \"I'\": 21,\n",
       " 'midst': 12,\n",
       " 'body,': 30,\n",
       " 'idle': 45,\n",
       " 'unactive,': 3,\n",
       " 'Still': 10,\n",
       " 'cupboarding': 3,\n",
       " 'viand,': 3,\n",
       " 'never': 593,\n",
       " 'bearing': 33,\n",
       " 'Like': 45,\n",
       " 'labour': 36,\n",
       " 'rest,': 66,\n",
       " 'instruments': 27,\n",
       " 'Did': 46,\n",
       " 'see': 743,\n",
       " 'hear,': 57,\n",
       " 'devise,': 6,\n",
       " 'instruct,': 3,\n",
       " 'walk,': 9,\n",
       " 'feel,': 12,\n",
       " 'And,': 125,\n",
       " 'mutually': 6,\n",
       " 'participate,': 3,\n",
       " 'minister': 24,\n",
       " 'Unto': 21,\n",
       " 'appetite': 12,\n",
       " 'affection': 25,\n",
       " 'common': 120,\n",
       " 'whole': 39,\n",
       " 'body.': 15,\n",
       " 'belly': 18,\n",
       " \"answer'd--\": 3,\n",
       " 'answer': 166,\n",
       " 'made': 594,\n",
       " 'belly?': 3,\n",
       " 'Sir,': 75,\n",
       " 'kind': 156,\n",
       " 'smile,': 13,\n",
       " 'Which': 250,\n",
       " 'came': 245,\n",
       " 'from': 1773,\n",
       " 'lungs,': 3,\n",
       " 'thus--': 3,\n",
       " 'For,': 20,\n",
       " 'look': 399,\n",
       " 'smile': 34,\n",
       " 'As': 379,\n",
       " 'speak--it': 3,\n",
       " 'tauntingly': 3,\n",
       " 'replied': 3,\n",
       " 'discontented': 18,\n",
       " 'members,': 6,\n",
       " 'mutinous': 15,\n",
       " 'parts': 24,\n",
       " 'envied': 5,\n",
       " 'receipt;': 3,\n",
       " 'so': 2491,\n",
       " 'fitly': 6,\n",
       " 'malign': 3,\n",
       " 'senators': 18,\n",
       " 'such': 809,\n",
       " \"belly's\": 6,\n",
       " 'answer?': 9,\n",
       " 'What!': 16,\n",
       " 'kingly-crowned': 3,\n",
       " 'head,': 86,\n",
       " 'vigilant': 3,\n",
       " 'eye,': 69,\n",
       " 'counsellor': 3,\n",
       " 'heart,': 108,\n",
       " 'arm': 78,\n",
       " 'soldier,': 24,\n",
       " 'steed': 6,\n",
       " 'leg,': 6,\n",
       " 'tongue': 191,\n",
       " 'trumpeter.': 3,\n",
       " 'muniments': 3,\n",
       " 'petty': 18,\n",
       " 'helps': 15,\n",
       " 'In': 239,\n",
       " 'fabric,': 3,\n",
       " 'they--': 3,\n",
       " 'then?': 72,\n",
       " \"'Fore\": 3,\n",
       " 'me,': 851,\n",
       " 'fellow': 80,\n",
       " 'speaks!': 3,\n",
       " 'Should': 46,\n",
       " 'cormorant': 3,\n",
       " \"restrain'd,\": 3,\n",
       " 'Who': 127,\n",
       " 'sink': 11,\n",
       " 'body,--': 3,\n",
       " 'former': 42,\n",
       " 'agents,': 3,\n",
       " 'complain,': 6,\n",
       " \"you'll\": 114,\n",
       " 'bestow': 12,\n",
       " 'small--of': 3,\n",
       " 'little--': 3,\n",
       " 'Patience': 4,\n",
       " 'awhile,': 24,\n",
       " 'answer.': 30,\n",
       " \"Ye're\": 1,\n",
       " 'long': 250,\n",
       " 'about': 218,\n",
       " 'it.': 438,\n",
       " 'Note': 2,\n",
       " 'this,': 173,\n",
       " 'friend;': 12,\n",
       " 'grave': 99,\n",
       " 'deliberate,': 3,\n",
       " 'Not': 110,\n",
       " 'rash': 18,\n",
       " 'accusers,': 3,\n",
       " \"answer'd:\": 3,\n",
       " \"'True\": 1,\n",
       " 'incorporate': 6,\n",
       " \"friends,'\": 6,\n",
       " 'quoth': 60,\n",
       " 'he,': 143,\n",
       " \"'That\": 1,\n",
       " 'receive': 40,\n",
       " 'general': 78,\n",
       " 'food': 15,\n",
       " 'first,': 91,\n",
       " 'do': 1978,\n",
       " 'live': 224,\n",
       " 'upon;': 9,\n",
       " 'fit': 84,\n",
       " 'Because': 30,\n",
       " 'am': 1283,\n",
       " 'store-house': 3,\n",
       " 'shop': 9,\n",
       " 'body:': 6,\n",
       " 'remember,': 17,\n",
       " 'send': 170,\n",
       " 'through': 142,\n",
       " 'rivers': 20,\n",
       " 'blood,': 122,\n",
       " 'Even': 71,\n",
       " 'court,': 15,\n",
       " 'seat': 39,\n",
       " 'brain;': 3,\n",
       " 'cranks': 3,\n",
       " 'offices': 9,\n",
       " 'man,': 177,\n",
       " 'strongest': 3,\n",
       " 'nerves': 9,\n",
       " 'small': 60,\n",
       " 'inferior': 12,\n",
       " 'veins': 18,\n",
       " 'From': 90,\n",
       " 'natural': 30,\n",
       " 'competency': 3,\n",
       " 'Whereby': 2,\n",
       " 'live:': 21,\n",
       " 'once,': 37,\n",
       " 'You,': 15,\n",
       " \"friends,'--this\": 3,\n",
       " 'says': 116,\n",
       " 'mark': 111,\n",
       " 'me,--': 3,\n",
       " 'Ay,': 152,\n",
       " 'sir;': 177,\n",
       " 'well,': 355,\n",
       " 'well.': 144,\n",
       " \"'Though\": 1,\n",
       " 'once': 245,\n",
       " 'See': 22,\n",
       " 'deliver': 49,\n",
       " 'out': 623,\n",
       " 'each,': 3,\n",
       " 'Yet': 83,\n",
       " 'audit': 3,\n",
       " 'back': 155,\n",
       " 'flour': 3,\n",
       " 'all,': 159,\n",
       " 'And': 1801,\n",
       " 'leave': 374,\n",
       " \"bran.'\": 3,\n",
       " \"to't?\": 9,\n",
       " 'It': 176,\n",
       " 'answer:': 9,\n",
       " 'how': 1240,\n",
       " 'apply': 9,\n",
       " 'this?': 120,\n",
       " 'Rome': 35,\n",
       " 'members;': 3,\n",
       " 'examine': 7,\n",
       " 'Their': 30,\n",
       " 'counsels': 9,\n",
       " 'cares,': 3,\n",
       " 'digest': 11,\n",
       " 'things': 153,\n",
       " 'rightly': 9,\n",
       " 'Touching': 4,\n",
       " 'weal': 6,\n",
       " 'common,': 3,\n",
       " 'find': 265,\n",
       " 'public': 21,\n",
       " 'benefit': 36,\n",
       " 'But': 537,\n",
       " 'proceeds': 6,\n",
       " 'or': 1526,\n",
       " 'yourselves.': 12,\n",
       " 'think,': 84,\n",
       " 'great': 438,\n",
       " 'toe': 3,\n",
       " 'assembly?': 3,\n",
       " 'toe!': 3,\n",
       " 'toe?': 3,\n",
       " 'that,': 231,\n",
       " 'lowest,': 3,\n",
       " 'basest,': 3,\n",
       " 'poorest,': 3,\n",
       " 'wise': 57,\n",
       " 'rebellion,': 9,\n",
       " 'thou': 3687,\n",
       " \"go'st\": 6,\n",
       " 'foremost:': 3,\n",
       " 'Thou': 204,\n",
       " 'rascal,': 6,\n",
       " 'art': 557,\n",
       " 'worst': 50,\n",
       " 'blood': 318,\n",
       " 'run,': 15,\n",
       " \"Lead'st\": 1,\n",
       " 'first': 692,\n",
       " 'win': 83,\n",
       " 'some': 871,\n",
       " 'vantage.': 12,\n",
       " 'ready': 81,\n",
       " 'stiff': 9,\n",
       " 'clubs:': 3,\n",
       " 'her': 1912,\n",
       " 'rats': 12,\n",
       " 'point': 66,\n",
       " 'battle;': 15,\n",
       " 'bale.': 3,\n",
       " 'Hail,': 5,\n",
       " 'noble': 505,\n",
       " 'Marcius!': 7,\n",
       " 'MARCIUS:': 41,\n",
       " 'Thanks.': 1,\n",
       " \"What's\": 41,\n",
       " 'matter,': 39,\n",
       " 'dissentious': 8,\n",
       " 'rogues,': 3,\n",
       " 'That,': 24,\n",
       " 'rubbing': 3,\n",
       " 'itch': 3,\n",
       " 'opinion,': 21,\n",
       " 'Make': 34,\n",
       " 'scabs?': 3,\n",
       " 'word.': 45,\n",
       " 'He': 262,\n",
       " 'words': 173,\n",
       " 'thee': 1265,\n",
       " 'flatter': 38,\n",
       " 'Beneath': 1,\n",
       " 'abhorring.': 3,\n",
       " 'have,': 83,\n",
       " 'curs,': 3,\n",
       " 'nor': 616,\n",
       " 'peace': 142,\n",
       " 'war?': 6,\n",
       " 'affrights': 5,\n",
       " 'makes': 240,\n",
       " 'trusts': 3,\n",
       " 'Where': 149,\n",
       " 'should': 1016,\n",
       " 'lions,': 3,\n",
       " 'finds': 29,\n",
       " 'hares;': 3,\n",
       " 'foxes,': 3,\n",
       " 'geese:': 3,\n",
       " 'surer,': 3,\n",
       " 'no,': 358,\n",
       " 'Than': 137,\n",
       " 'coal': 3,\n",
       " 'fire': 81,\n",
       " 'upon': 1042,\n",
       " 'ice,': 6,\n",
       " 'hailstone': 3,\n",
       " 'sun.': 24,\n",
       " 'virtue': 67,\n",
       " 'worthy': 151,\n",
       " 'offence': 36,\n",
       " 'subdues': 5,\n",
       " 'justice': 76,\n",
       " 'deserves': 34,\n",
       " 'greatness': 15,\n",
       " 'Deserves': 2,\n",
       " 'hate;': 9,\n",
       " 'affections': 15,\n",
       " 'sick': 42,\n",
       " \"man's\": 72,\n",
       " 'appetite,': 9,\n",
       " 'desires': 19,\n",
       " 'increase': 18,\n",
       " 'evil.': 3,\n",
       " 'depends': 6,\n",
       " 'Upon': 68,\n",
       " 'favours': 20,\n",
       " 'swims': 3,\n",
       " 'fins': 3,\n",
       " 'lead': 53,\n",
       " 'hews': 3,\n",
       " 'down': 247,\n",
       " 'oaks': 3,\n",
       " 'rushes.': 3,\n",
       " 'Hang': 6,\n",
       " 'ye!': 3,\n",
       " 'Trust': 5,\n",
       " 'Ye?': 1,\n",
       " 'every': 284,\n",
       " 'minute': 18,\n",
       " 'change': 88,\n",
       " 'mind,': 33,\n",
       " 'call': 390,\n",
       " 'hate,': 48,\n",
       " 'Him': 5,\n",
       " 'vile': 44,\n",
       " 'garland.': 9,\n",
       " 'these': 805,\n",
       " 'several': 39,\n",
       " 'places': 20,\n",
       " 'cry': 113,\n",
       " 'senate,': 15,\n",
       " 'who,': 77,\n",
       " 'Under': 17,\n",
       " 'keep': 281,\n",
       " 'awe,': 6,\n",
       " 'else': 247,\n",
       " 'feed': 26,\n",
       " 'another?': 3,\n",
       " 'seeking?': 3,\n",
       " 'rates;': 3,\n",
       " 'whereof,': 15,\n",
       " 'say,': 296,\n",
       " 'stored.': 3,\n",
       " \"'em!\": 9,\n",
       " 'say!': 24,\n",
       " \"They'll\": 6,\n",
       " 'sit': 134,\n",
       " 'fire,': 42,\n",
       " 'presume': 12,\n",
       " \"i'\": 246,\n",
       " 'Capitol;': 3,\n",
       " \"who's\": 39,\n",
       " 'rise,': 17,\n",
       " 'thrives': 6,\n",
       " 'declines;': 3,\n",
       " 'factions': 3,\n",
       " 'Conjectural': 1,\n",
       " 'marriages;': 3,\n",
       " 'making': 50,\n",
       " 'parties': 9,\n",
       " 'feebling': 3,\n",
       " 'stand': 324,\n",
       " 'liking': 9,\n",
       " 'Below': 2,\n",
       " 'cobbled': 3,\n",
       " 'shoes.': 3,\n",
       " 'grain': 18,\n",
       " 'enough!': 6,\n",
       " 'nobility': 15,\n",
       " 'lay': 194,\n",
       " 'aside': 30,\n",
       " 'ruth,': 6,\n",
       " 'use': 191,\n",
       " 'sword,': 59,\n",
       " 'quarry': 3,\n",
       " 'thousands': 12,\n",
       " \"quarter'd\": 3,\n",
       " 'slaves,': 15,\n",
       " 'high': 145,\n",
       " 'pick': 6,\n",
       " 'lance.': 3,\n",
       " 'almost': 79,\n",
       " 'thoroughly': 6,\n",
       " 'persuaded;': 3,\n",
       " 'abundantly': 3,\n",
       " 'lack': 48,\n",
       " 'discretion,': 3,\n",
       " 'passing': 42,\n",
       " 'cowardly.': 3,\n",
       " 'beseech': 196,\n",
       " 'troop?': 3,\n",
       " 'dissolved:': 3,\n",
       " 'hang': 63,\n",
       " 'said': 188,\n",
       " 'an-hungry;': 3,\n",
       " \"sigh'd\": 11,\n",
       " 'forth': 198,\n",
       " 'proverbs,': 3,\n",
       " 'broke': 50,\n",
       " 'stone': 30,\n",
       " 'walls,': 24,\n",
       " 'dogs': 17,\n",
       " 'eat,': 12,\n",
       " 'meat': 21,\n",
       " 'mouths,': 15,\n",
       " 'sent': 132,\n",
       " 'Corn': 1,\n",
       " 'rich': 73,\n",
       " 'only:': 3,\n",
       " 'shreds': 3,\n",
       " 'vented': 3,\n",
       " 'complainings;': 3,\n",
       " \"answer'd,\": 3,\n",
       " 'petition': 15,\n",
       " 'granted': 30,\n",
       " 'strange': 89,\n",
       " 'one--': 3,\n",
       " 'break': 136,\n",
       " 'heart': 360,\n",
       " 'generosity,': 3,\n",
       " 'bold': 71,\n",
       " 'power': 185,\n",
       " 'pale--they': 3,\n",
       " 'threw': 13,\n",
       " 'caps': 18,\n",
       " 'horns': 6,\n",
       " 'moon,': 24,\n",
       " 'Shouting': 1,\n",
       " 'emulation.': 3,\n",
       " 'them?': 39,\n",
       " 'Five': 6,\n",
       " 'tribunes': 39,\n",
       " 'defend': 60,\n",
       " 'vulgar': 9,\n",
       " 'wisdoms,': 3,\n",
       " 'choice:': 6,\n",
       " \"one's\": 6,\n",
       " 'Junius': 1,\n",
       " 'Brutus,': 1,\n",
       " 'Sicinius': 1,\n",
       " 'Velutus,': 1,\n",
       " \"not--'Sdeath!\": 1,\n",
       " 'rabble': 6,\n",
       " \"unroof'd\": 3,\n",
       " 'city,': 23,\n",
       " 'Ere': 28,\n",
       " \"prevail'd\": 15,\n",
       " 'me:': 186,\n",
       " 'Win': 1,\n",
       " 'throw': 76,\n",
       " 'greater': 65,\n",
       " 'themes': 3,\n",
       " \"insurrection's\": 3,\n",
       " 'arguing.': 3,\n",
       " 'This': 223,\n",
       " 'strange.': 15,\n",
       " 'Go,': 57,\n",
       " 'get': 172,\n",
       " 'home,': 81,\n",
       " 'fragments!': 3,\n",
       " 'Messenger:': 45,\n",
       " \"Where's\": 14,\n",
       " 'Here:': 1,\n",
       " \"what's\": 208,\n",
       " 'news': 152,\n",
       " 'Volsces': 14,\n",
       " 'arms.': 39,\n",
       " 'glad': 61,\n",
       " \"'t:\": 15,\n",
       " 'then': 1066,\n",
       " \"ha'\": 20,\n",
       " 'means': 132,\n",
       " 'vent': 9,\n",
       " 'musty': 12,\n",
       " 'superfluity.': 3,\n",
       " 'See,': 15,\n",
       " 'best': 238,\n",
       " 'elders.': 6,\n",
       " 'Senator:': 43,\n",
       " 'Marcius,': 22,\n",
       " \"'tis\": 837,\n",
       " 'true': 315,\n",
       " 'lately': 20,\n",
       " 'told': 150,\n",
       " 'us;': 27,\n",
       " 'leader,': 3,\n",
       " 'Tullus': 4,\n",
       " 'Aufidius,': 15,\n",
       " 'put': 324,\n",
       " \"'t.\": 24,\n",
       " 'sin': 77,\n",
       " 'envying': 6,\n",
       " 'nobility,': 3,\n",
       " 'thing': 234,\n",
       " 'am,': 39,\n",
       " 'wish': 131,\n",
       " 'he.': 15,\n",
       " 'COMINIUS:': 67,\n",
       " 'fought': 42,\n",
       " 'together.': 18,\n",
       " 'Were': 60,\n",
       " 'half': 97,\n",
       " 'world': 216,\n",
       " 'ears': 69,\n",
       " 'party,': 9,\n",
       " \"I'ld\": 16,\n",
       " 'revolt': 11,\n",
       " 'Only': 10,\n",
       " 'him:': 159,\n",
       " 'lion': 30,\n",
       " 'proud': 114,\n",
       " 'hunt.': 3,\n",
       " 'Then,': 39,\n",
       " 'Attend': 4,\n",
       " 'Cominius': 6,\n",
       " 'wars.': 15,\n",
       " 'promise.': 6,\n",
       " 'is;': 21,\n",
       " 'constant.': 3,\n",
       " 'Titus': 7,\n",
       " 'Lartius,': 4,\n",
       " 'Shalt': 6,\n",
       " 'strike': 93,\n",
       " \"Tullus'\": 1,\n",
       " 'face.': 45,\n",
       " 'What,': 116,\n",
       " 'stiff?': 3,\n",
       " \"stand'st\": 6,\n",
       " 'out?': 12,\n",
       " 'TITUS:': 2,\n",
       " 'No,': 113,\n",
       " 'Marcius;': 3,\n",
       " 'lean': 15,\n",
       " 'crutch': 3,\n",
       " 'fight': 99,\n",
       " \"t'other,\": 3,\n",
       " 'behind': 40,\n",
       " 'business.': 30,\n",
       " 'O,': 260,\n",
       " 'true-bred!': 3,\n",
       " 'company': 33,\n",
       " 'where,': 24,\n",
       " 'know,': 122,\n",
       " 'greatest': 27,\n",
       " 'friends': 158,\n",
       " 'attend': 80,\n",
       " 'Noble': 8,\n",
       " 'follow:': 6,\n",
       " 'much': 534,\n",
       " 'corn;': 3,\n",
       " 'take': 804,\n",
       " 'thither': 42,\n",
       " 'gnaw': 6,\n",
       " 'garners.': 3,\n",
       " 'Worshipful': 1,\n",
       " 'mutiners,': 3,\n",
       " 'valour': 33,\n",
       " 'puts': 32,\n",
       " 'forth:': 3,\n",
       " 'pray,': 102,\n",
       " 'follow.': 17,\n",
       " 'SICINIUS:': 117,\n",
       " 'Was': 56,\n",
       " 'man': 573,\n",
       " 'BRUTUS:': 91,\n",
       " 'equal.': 3,\n",
       " 'chosen': 9,\n",
       " 'people,--': 3,\n",
       " \"Mark'd\": 4,\n",
       " 'lip': 18,\n",
       " 'eyes?': 12,\n",
       " 'Nay.': 1,\n",
       " 'taunts.': 3,\n",
       " 'Being': 34,\n",
       " 'moved,': 12,\n",
       " 'spare': 34,\n",
       " 'gird': 3,\n",
       " 'gods.': 9,\n",
       " 'Be-mock': 1,\n",
       " 'modest': 18,\n",
       " 'moon.': 12,\n",
       " 'present': 146,\n",
       " 'devour': 9,\n",
       " 'grown': 50,\n",
       " 'Too': 22,\n",
       " 'valiant.': 3,\n",
       " ...}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "0141a927",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rmgup\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rmgup\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "68088e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "6a134ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "9c3f222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from gensim.models import Word2Vec as w2v\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# constants\n",
    "PATH = 'shakespeare.txt'\n",
    "sw = stopwords.words('english')\n",
    "plt.style.use('ggplot')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# import data\n",
    "lines = []\n",
    "with open(PATH, 'r') as f:\n",
    "    for l in f:\n",
    "        lines.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "da3ec7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove new lines\n",
    "lines = [line.rstrip('\\n') for line in lines]\n",
    "\n",
    "# make all characters lower\n",
    "lines = [line.lower() for line in lines]\n",
    "\n",
    "# remove punctuations from each line\n",
    "lines = [line.translate(str.maketrans('', '', string.punctuation)) for line in lines]\n",
    "\n",
    "# tokenize\n",
    "lines = [word_tokenize(line) for line in lines]\n",
    "\n",
    "def remove_stopwords(lines, sw = sw):\n",
    "    '''\n",
    "    The purpose of this function is to remove stopwords from a given array of \n",
    "    lines.\n",
    "    \n",
    "    params:\n",
    "        lines (Array / List) : The list of lines you want to remove the stopwords from\n",
    "        sw (Set) : The set of stopwords you want to remove\n",
    "        \n",
    "    example:\n",
    "        lines = remove_stopwords(lines = lines, sw = sw)\n",
    "    '''\n",
    "    \n",
    "    res = []\n",
    "    for line in lines:\n",
    "        original = line\n",
    "        line = [w for w in line if w not in sw]\n",
    "        if len(line) < 1:\n",
    "            line = original\n",
    "        res.append(line)\n",
    "    return res\n",
    "    \n",
    "filtered_lines = remove_stopwords(lines = lines, sw = sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "aedc62e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('capulet', 0.8013245463371277), ('anne', 0.7930781245231628), ('grey', 0.790635883808136), ('watchman', 0.7859889268875122), ('third', 0.7754901051521301), ('gentleman', 0.7715964913368225), ('servingman', 0.768513560295105), ('servant', 0.7676213383674622), ('emulation', 0.7654891014099121), ('senator', 0.7646733522415161)]\n",
      "(4820, 100)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>thou</th>\n",
       "      <td>-0.111388</td>\n",
       "      <td>0.102634</td>\n",
       "      <td>0.311327</td>\n",
       "      <td>0.391375</td>\n",
       "      <td>-0.109722</td>\n",
       "      <td>-0.516248</td>\n",
       "      <td>0.105045</td>\n",
       "      <td>0.652980</td>\n",
       "      <td>-0.378833</td>\n",
       "      <td>-0.461947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297181</td>\n",
       "      <td>0.083107</td>\n",
       "      <td>0.344467</td>\n",
       "      <td>0.126841</td>\n",
       "      <td>0.428538</td>\n",
       "      <td>0.381706</td>\n",
       "      <td>-0.327570</td>\n",
       "      <td>-0.119157</td>\n",
       "      <td>0.108152</td>\n",
       "      <td>0.194188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thy</th>\n",
       "      <td>-0.156386</td>\n",
       "      <td>0.156076</td>\n",
       "      <td>0.121290</td>\n",
       "      <td>0.073916</td>\n",
       "      <td>0.048472</td>\n",
       "      <td>-0.269125</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>0.590788</td>\n",
       "      <td>-0.183441</td>\n",
       "      <td>-0.304440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286010</td>\n",
       "      <td>0.042137</td>\n",
       "      <td>0.163752</td>\n",
       "      <td>0.093177</td>\n",
       "      <td>0.256759</td>\n",
       "      <td>0.341058</td>\n",
       "      <td>0.092665</td>\n",
       "      <td>-0.099154</td>\n",
       "      <td>-0.013104</td>\n",
       "      <td>0.055094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king</th>\n",
       "      <td>-0.359416</td>\n",
       "      <td>0.264884</td>\n",
       "      <td>-0.020950</td>\n",
       "      <td>-0.164251</td>\n",
       "      <td>-0.189976</td>\n",
       "      <td>-0.219396</td>\n",
       "      <td>0.034088</td>\n",
       "      <td>0.887656</td>\n",
       "      <td>-0.482256</td>\n",
       "      <td>-0.410423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.349370</td>\n",
       "      <td>-0.124983</td>\n",
       "      <td>0.585505</td>\n",
       "      <td>0.131956</td>\n",
       "      <td>0.677724</td>\n",
       "      <td>0.248554</td>\n",
       "      <td>0.805573</td>\n",
       "      <td>-0.267610</td>\n",
       "      <td>0.403081</td>\n",
       "      <td>-0.457073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shall</th>\n",
       "      <td>-0.036365</td>\n",
       "      <td>0.168755</td>\n",
       "      <td>0.061335</td>\n",
       "      <td>-0.053515</td>\n",
       "      <td>0.018322</td>\n",
       "      <td>-0.152417</td>\n",
       "      <td>0.058797</td>\n",
       "      <td>0.487652</td>\n",
       "      <td>-0.114386</td>\n",
       "      <td>-0.189049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.327524</td>\n",
       "      <td>-0.033843</td>\n",
       "      <td>0.078596</td>\n",
       "      <td>0.011499</td>\n",
       "      <td>0.326723</td>\n",
       "      <td>0.264412</td>\n",
       "      <td>0.164724</td>\n",
       "      <td>-0.066832</td>\n",
       "      <td>-0.106096</td>\n",
       "      <td>0.040973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thee</th>\n",
       "      <td>0.008642</td>\n",
       "      <td>0.129900</td>\n",
       "      <td>0.075459</td>\n",
       "      <td>0.096226</td>\n",
       "      <td>0.056678</td>\n",
       "      <td>-0.212622</td>\n",
       "      <td>0.051666</td>\n",
       "      <td>0.499368</td>\n",
       "      <td>-0.125888</td>\n",
       "      <td>-0.255334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.369448</td>\n",
       "      <td>0.078539</td>\n",
       "      <td>0.043195</td>\n",
       "      <td>0.106807</td>\n",
       "      <td>0.279182</td>\n",
       "      <td>0.371100</td>\n",
       "      <td>-0.035646</td>\n",
       "      <td>-0.009103</td>\n",
       "      <td>-0.142610</td>\n",
       "      <td>0.125969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6   \\\n",
       "thou  -0.111388  0.102634  0.311327  0.391375 -0.109722 -0.516248  0.105045   \n",
       "thy   -0.156386  0.156076  0.121290  0.073916  0.048472 -0.269125  0.005583   \n",
       "king  -0.359416  0.264884 -0.020950 -0.164251 -0.189976 -0.219396  0.034088   \n",
       "shall -0.036365  0.168755  0.061335 -0.053515  0.018322 -0.152417  0.058797   \n",
       "thee   0.008642  0.129900  0.075459  0.096226  0.056678 -0.212622  0.051666   \n",
       "\n",
       "             7         8         9   ...        90        91        92  \\\n",
       "thou   0.652980 -0.378833 -0.461947  ...  0.297181  0.083107  0.344467   \n",
       "thy    0.590788 -0.183441 -0.304440  ...  0.286010  0.042137  0.163752   \n",
       "king   0.887656 -0.482256 -0.410423  ...  0.349370 -0.124983  0.585505   \n",
       "shall  0.487652 -0.114386 -0.189049  ...  0.327524 -0.033843  0.078596   \n",
       "thee   0.499368 -0.125888 -0.255334  ...  0.369448  0.078539  0.043195   \n",
       "\n",
       "             93        94        95        96        97        98        99  \n",
       "thou   0.126841  0.428538  0.381706 -0.327570 -0.119157  0.108152  0.194188  \n",
       "thy    0.093177  0.256759  0.341058  0.092665 -0.099154 -0.013104  0.055094  \n",
       "king   0.131956  0.677724  0.248554  0.805573 -0.267610  0.403081 -0.457073  \n",
       "shall  0.011499  0.326723  0.264412  0.164724 -0.066832 -0.106096  0.040973  \n",
       "thee   0.106807  0.279182  0.371100 -0.035646 -0.009103 -0.142610  0.125969  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = w2v(\n",
    "    filtered_lines,\n",
    "    min_count=3,  \n",
    "    sg = 1,       \n",
    "    window=7      \n",
    ")       \n",
    "\n",
    "print(w.wv.most_similar('lady'))\n",
    "\n",
    "emb_df = (\n",
    "    pd.DataFrame(\n",
    "        [w.wv.get_vector(str(n)) for n in w.wv.key_to_index],\n",
    "        index = w.wv.key_to_index\n",
    "    )\n",
    ")\n",
    "print(emb_df.shape)\n",
    "emb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "13d3ea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "info = api.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "4feaff6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 104.8/104.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "model = api.load(\"glove-twitter-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "eb35c729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.keyedvectors.KeyedVectors"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ab3e2358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.77069  ,  0.12827  ,  0.33137  ,  0.0050893, -0.47605  ,\n",
       "       -0.50116  ,  1.858    ,  1.0624   , -0.56511  ,  0.13328  ,\n",
       "       -0.41918  , -0.14195  , -2.8555   , -0.57131  , -0.13418  ,\n",
       "       -0.44922  ,  0.48591  , -0.6479   , -0.84238  ,  0.61669  ,\n",
       "       -0.19824  , -0.57967  , -0.65885  ,  0.43928  , -0.50473  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[\"hello\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "23d45405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dd4bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
